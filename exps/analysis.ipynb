{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue = '#1f77b4'\n",
    "light_blue = '#aec7e8'\n",
    "orange = '#ff7f0e'\n",
    "light_orange = '#ffbb78'\n",
    "gray = '#60636a'\n",
    "light_gray = '#a5acaf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the tweets and bot scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_objects(path_to_file):\n",
    "    \"\"\"\n",
    "    Function to load JSON objects from .jsons file.\n",
    "    Each line of the .jsons file should be a serialized JSON object \n",
    "    \"\"\"\n",
    "    json_objects = []\n",
    "    with open(path_to_file) as f:\n",
    "        for line in f:\n",
    "            json_object = json.loads(line)\n",
    "            json_objects.append(json_object)\n",
    "    return json_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shib_tweets = load_json_objects(\"../data/shib_tweets.jsons\")\n",
    "shib_bot_scores = load_json_objects(\"../data/shib_bot_scores.jsons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floki_tweets = load_json_objects(\"../data/floki_tweets.jsons\")\n",
    "floki_bot_scores = load_json_objects(\"../data/floki_bot_scores.jsons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_tweets = load_json_objects(\"../data/aapl_tweets.jsons\")\n",
    "aapl_bot_scores = load_json_objects(\"../data/aapl_bot_scores.jsons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the tweets and bot scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info = []\n",
    "for tweet in shib_tweets:\n",
    "    tweet_info.append([\n",
    "        tweet['id_str'],\n",
    "        tweet['user']['id_str'],\n",
    "        'shib'\n",
    "    ])\n",
    "\n",
    "for tweet in floki_tweets:\n",
    "    tweet_info.append([\n",
    "        tweet['id_str'],\n",
    "        tweet['user']['id_str'],\n",
    "        'floki'\n",
    "    ])\n",
    "    \n",
    "for tweet in aapl_tweets:\n",
    "    tweet_info.append([\n",
    "        tweet['id_str'],\n",
    "        tweet['user']['id_str'],\n",
    "        'aapl'\n",
    "    ])\n",
    "\n",
    "tweet_info_df = pd.DataFrame(tweet_info, columns=['tid', 'user_id', 'cashtag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_scores = []\n",
    "for bot_score in shib_bot_scores:\n",
    "    bot_scores.append([\n",
    "        bot_score['user']['user_data']['id_str'],\n",
    "        bot_score['user']['majority_lang'],\n",
    "        bot_score['raw_scores']['english']['overall'],\n",
    "        bot_score['raw_scores']['universal']['overall']\n",
    "    ])\n",
    "    \n",
    "for bot_score in floki_bot_scores:\n",
    "    bot_scores.append([\n",
    "        bot_score['user']['user_data']['id_str'],\n",
    "        bot_score['user']['majority_lang'],\n",
    "        bot_score['raw_scores']['english']['overall'],\n",
    "        bot_score['raw_scores']['universal']['overall']\n",
    "    ])\n",
    "    \n",
    "\n",
    "for bot_score in aapl_bot_scores:\n",
    "    bot_scores.append([\n",
    "        bot_score['user']['user_data']['id_str'],\n",
    "        bot_score['user']['majority_lang'],\n",
    "        bot_score['raw_scores']['english']['overall'],\n",
    "        bot_score['raw_scores']['universal']['overall']\n",
    "    ])\n",
    "    \n",
    "bot_scores_df = pd.DataFrame(bot_scores, columns=['user_id', 'lang', 'eng', 'uni'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_scores_df.drop_duplicates(subset=['user_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_with_bot_score_df = tweet_info_df.merge(bot_scores_df, on='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the number of tweets and unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_info_df.groupby(\"cashtag\").agg({\n",
    "    'tid': 'nunique',\n",
    "    'user_id': 'nunique'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the use of different language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_freq = bot_scores_df.lang.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_code_map = {\n",
    "    'en': \"English\",\n",
    "    'ja': \"Japanese\",\n",
    "    'und': \"Unknown\",\n",
    "    'es': \"Spanish\",\n",
    "    'tr': \"Turkish\",\n",
    "    'ar': \"Arabic\",\n",
    "    'fr': \"French\",\n",
    "    'in': \"Hindi\",\n",
    "    'pt': \"Portuguese\",\n",
    "    'it': \"Italian\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_labels = []\n",
    "lang_freq_count = []\n",
    "for index, freq in lang_freq.head(6).iteritems():\n",
    "    lang_labels.append(f\"{lang_code_map.get(index)} ({freq / lang_freq.sum()*100:.1f}%)\")\n",
    "    lang_freq_count.append(freq)\n",
    "    \n",
    "lang_labels.append(f\"Others ({lang_freq.tail(-6).sum() / lang_freq.sum()*100:.1f}%)\")\n",
    "lang_freq_count.append(lang_freq.tail(-6).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "colors = [\n",
    "    \"#aec7e8\",\n",
    "    \"#ffbb78\",\n",
    "    \"#98df8a\",\n",
    "    \"#ff9896\",\n",
    "    \"#c5b0d5\",\n",
    "    \"#c49c94\",\n",
    "    \"#f7b6d2\",\n",
    "]\n",
    "plt.pie(\n",
    "    lang_freq_count,\n",
    "    labels=lang_labels,\n",
    "    colors=colors,\n",
    "    counterclock=False,\n",
    "    startangle=-35)\n",
    "plt.gca().axis('equal');\n",
    "plt.savefig(\"figures/language_freqency.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the bot score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_to_plot = [\n",
    "    [1, 'shib', light_blue, '$SHIB'],\n",
    "    [2, 'floki', light_orange, '$FLOKI'],\n",
    "    [3, 'aapl', light_gray, '$AAPL']\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(5.5, 4.5))\n",
    "for index, key, color, title in dist_to_plot:\n",
    "    plt.subplot(3, 1, index)\n",
    "    plt.hist(\n",
    "        tweet_with_bot_score_df.query(f'cashtag == \"{key}\"').eng,\n",
    "        bins=50,\n",
    "        color=color,\n",
    "    );\n",
    "    plt.annotate(title, xy=(0.03,0.7), xycoords='axes fraction')\n",
    "    if index<3:\n",
    "        plt.gca().set_xticklabels([])\n",
    "    if index == 2:\n",
    "        plt.ylabel(\"Frequency\")\n",
    "    if index==3:\n",
    "        plt.xlabel('Bot score')\n",
    "        \n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.ylim([0, 150])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/bot_score_dist.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4.5))\n",
    "for index, key, color, title in dist_to_plot:\n",
    "    box = plt.boxplot(\n",
    "        [\n",
    "            tweet_with_bot_score_df.query(f'cashtag == \"{key}\"').eng\n",
    "        ],\n",
    "        positions=[4 - index],\n",
    "        widths=0.3,\n",
    "        patch_artist=True,\n",
    "        notch=False,\n",
    "        whis=(5, 95),\n",
    "        vert=False,\n",
    "        showmeans=True\n",
    "    );\n",
    "    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']:\n",
    "            plt.setp(box[item], color=color)\n",
    "    plt.setp(box['medians'], color='white', lw=1.2)\n",
    "    plt.setp(box[\"boxes\"], facecolor=color)\n",
    "    plt.setp(box[\"fliers\"], markerfacecolor=color, markeredgecolor='white', markersize=3, markeredgewidth=0.5)\n",
    "    plt.setp(box['whiskers'], lw=2.5)\n",
    "    plt.setp(box['caps'], lw=2.5)\n",
    "    plt.setp(box['means'], marker='o', markerfacecolor='white', markeredgecolor='white', markersize=3)\n",
    "plt.gca().xaxis.grid(which=\"major\", color='gray', linestyle='--', linewidth=1, alpha=0.2)\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "\n",
    "plt.yticks([3, 2, 1], ['$SHIB', '$FLOKI', '$AAPL'])\n",
    "plt.xlabel('Bot score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/bot_score_boxplot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4.5))\n",
    "for index, key, color, title in dist_to_plot:\n",
    "    box = plt.boxplot(\n",
    "        [\n",
    "            tweet_with_bot_score_df.query(f'cashtag == \"{key}\"').eng\n",
    "        ],\n",
    "        positions=[4 - index],\n",
    "        widths=0.3,\n",
    "        patch_artist=True,\n",
    "        notch=False,\n",
    "        whis=(5, 95),\n",
    "        vert=False\n",
    "    );\n",
    "    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']:\n",
    "            plt.setp(box[item], color=color)\n",
    "    plt.setp(box['medians'], color='white', lw=1.2)\n",
    "    plt.setp(box[\"boxes\"], facecolor=color)\n",
    "    plt.setp(box[\"fliers\"], markerfacecolor=color, markeredgecolor='white', markersize=3, markeredgewidth=0.5)\n",
    "    plt.setp(box['whiskers'], lw=2.5)\n",
    "    plt.setp(box['caps'], lw=2.5)\n",
    "plt.gca().xaxis.grid(which=\"major\", color='gray', linestyle='--', linewidth=1, alpha=0.2)\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "\n",
    "plt.yticks([3, 2, 1], ['$SHIB', '$FLOKI', '$AAPL'])\n",
    "plt.xlabel('Bot score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/bot_score_boxplot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(\n",
    "    tweet_with_bot_score_df.query('cashtag == \"shib\"').eng,\n",
    "    tweet_with_bot_score_df.query('cashtag == \"floki\"').eng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(\n",
    "    tweet_with_bot_score_df.query('cashtag == \"shib\"').eng,\n",
    "    tweet_with_bot_score_df.query('cashtag == \"aapl\"').eng\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(\n",
    "    tweet_with_bot_score_df.query('cashtag == \"floki\"').eng,\n",
    "    tweet_with_bot_score_df.query('cashtag == \"aapl\"').eng\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_with_bot_score_df.query('cashtag == \"shib\" and eng > 0.5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_with_bot_score_df.query('cashtag == \"floki\" and eng > 0.5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_with_bot_score_df.query('cashtag == \"aapl\" and eng > 0.5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_with_bot_score_df.query('cashtag == \"shib\" and eng > 0.7'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_with_bot_score_df.query('cashtag == \"floki\" and eng > 0.7'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet_with_bot_score_df.query('cashtag == \"aapl\" and eng > 0.7'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4.5))\n",
    "threshold = 0.5\n",
    "bot_pct = [\n",
    "    len(tweet_with_bot_score_df.query(f'cashtag == \"shib\" and eng > {threshold}')) / 2000,\n",
    "    len(tweet_with_bot_score_df.query(f'cashtag == \"floki\" and eng > {threshold}')) / 2000,\n",
    "    len(tweet_with_bot_score_df.query(f'cashtag == \"aapl\" and eng > {threshold}')) / 2000\n",
    "]\n",
    "plt.barh(\n",
    "    [3, 2, 1],\n",
    "    bot_pct,\n",
    "    height=0.3,\n",
    "    color=[light_blue, light_orange, light_gray]\n",
    ")\n",
    "\n",
    "for i, pct in enumerate(bot_pct):\n",
    "    plt.text(pct-0.06, 3 - i, f\"{pct*100:.1f}%\", color='white', ha='center', va='center')\n",
    "\n",
    "plt.ylim([0.5, 3.5])\n",
    "plt.xlim([0, 0.62])\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1))\n",
    "\n",
    "plt.gca().grid(axis='x', alpha=0.2, linestyle='--', linewidth=1,)\n",
    "\n",
    "plt.yticks([3, 2, 1], ['$SHIB', '$FLOKI', '$AAPL'])\n",
    "plt.xlabel(f\"Percentage of tweets from likely bots (>{threshold})\")\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/bot_percent_05.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 4.5))\n",
    "threshold = 0.7\n",
    "bot_pct = [\n",
    "    len(tweet_with_bot_score_df.query(f'cashtag == \"shib\" and eng > {threshold}')) / 2000,\n",
    "    len(tweet_with_bot_score_df.query(f'cashtag == \"floki\" and eng > {threshold}')) / 2000,\n",
    "    len(tweet_with_bot_score_df.query(f'cashtag == \"aapl\" and eng > {threshold}')) / 2000\n",
    "]\n",
    "plt.barh(\n",
    "    [3, 2, 1],\n",
    "    bot_pct,\n",
    "    height=0.3,\n",
    "    color=[light_blue, light_orange, light_gray]\n",
    ")\n",
    "\n",
    "for i, pct in enumerate(bot_pct):\n",
    "    plt.text(pct-0.04, 3 - i, f\"{pct*100:.1f}%\", color='white', ha='center', va='center')\n",
    "\n",
    "plt.ylim([0.5, 3.5])\n",
    "plt.xlim([0, 0.41])\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))\n",
    "\n",
    "plt.gca().grid(axis='x', alpha=0.2, linestyle='--', linewidth=1,)\n",
    "\n",
    "plt.yticks([3, 2, 1], ['$SHIB', '$FLOKI', '$AAPL'])\n",
    "plt.xlabel(f\"Percentage of tweets from likely bots (>{threshold})\")\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/bot_percent_07.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
